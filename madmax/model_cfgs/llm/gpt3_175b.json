{
    "name" : "GPT3_175B",
    "type" : "LLM",
    "bytes_per_nonemb_param" : 2,
    "bytes_per_emb_param" : 2,
    "entries_per_table" : 50257,
    "num_transformer_layers" : 96,
    "num_transformer_heads" : 96,
    "attention_dim" : 12288,
    "transformer_fc_dim" : 49152,
    "transformer_seq_len" : 2048
}